"""
OpenAI GPT íŒŒì¸íŠœë‹ ë°ì´í„° ì¤€ë¹„
MFCC ìŒì„± íŠ¹ì§• + Clova API ë°œìŒí‰ê°€ + í…ìŠ¤íŠ¸ â†’ GPT í•™ìŠµ ë°ì´í„°
"""

import pandas as pd
import json
from pathlib import Path
from typing import List, Dict


def create_openai_training_data(
    csv_path: str,
    output_path: str = "openai_training_data.jsonl",
    include_audio_features: bool = True
):
    """
    CSV ë°ì´í„°ë¥¼ OpenAI íŒŒì¸íŠœë‹ í˜•ì‹ìœ¼ë¡œ ë³€í™˜
    MFCC ìŒì„± íŠ¹ì§• í¬í•¨

    Args:
        csv_path: í”¼ë“œë°± CSV íŒŒì¼ (ìŒì„± íŠ¹ì§• í¬í•¨)
        output_path: ì¶œë ¥ JSONL íŒŒì¼
        include_audio_features: ìŒì„± íŠ¹ì§• í¬í•¨ ì—¬ë¶€
    """

    df = pd.read_csv(csv_path)

    training_data = []

    print(f"ğŸ“Š CSV íŒŒì¼ ë¡œë”©: {csv_path}")
    print(f"ì´ ìƒ˜í”Œ ìˆ˜: {len(df)}\n")

    # ìŒì„± íŠ¹ì§• ì»¬ëŸ¼ í™•ì¸
    has_audio_features = 'audio_summary' in df.columns
    if include_audio_features and not has_audio_features:
        print("âš ï¸  ìŒì„± íŠ¹ì§•ì´ CSVì— ì—†ìŠµë‹ˆë‹¤.")
        print("ë¨¼ì € extract_audio_features.pyë¥¼ ì‹¤í–‰í•˜ì„¸ìš”.\n")
        include_audio_features = False

    for idx, row in df.iterrows():
        # í•™ìƒ ë‹µë³€ í…ìŠ¤íŠ¸
        transcript = row['í…ìŠ¤íŠ¸']

        # êµì‚¬ í”¼ë“œë°± (ë°œìŒ/ìœ ì°½ì„±ì€ í…ìŠ¤íŠ¸ í”¼ë“œë°±)
        pronunciation_feedback = row.get('ë°œìŒ', '')
        fluency_feedback = row.get('fluency', '')

        # ì‹¤ì œ í‰ê°€ ì ìˆ˜ ë° í”¼ë“œë°±
        content_score = row.get('ë‚´ìš©', '')
        grammar_score = row.get('ë¬¸ë²•/í‘œí˜„', '')
        total_score = row.get('total_score', 0)
        feedback = row.get('í…ìŠ¤íŠ¸ í”¼ë“œë°±', '')

        # ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸
        system_message = """ë‹¹ì‹ ì€ TOEFL ìŠ¤í”¼í‚¹ í‰ê°€ ì „ë¬¸ê°€ì…ë‹ˆë‹¤.

ë‹¤ìŒ ì •ë³´ë¥¼ ë°›ì•„ í•™ìƒì˜ ë‹µë³€ì„ í‰ê°€í•©ë‹ˆë‹¤:
1. í•™ìƒì˜ ë‹µë³€ í…ìŠ¤íŠ¸
2. ìŒì„± íŠ¹ì§• ë¶„ì„ (MFCC, Pitch, Energy, íœ´ì§€, ë§í•˜ê¸° ì†ë„ ë“±)

ì•„ë˜ í•­ëª©ì„ í‰ê°€í•˜ì„¸ìš”:
- ë‚´ìš© (Content): ì§ˆë¬¸ ì í•©ì„±, ë…¼ë¦¬ì  êµ¬ì¡°, êµ¬ì²´ì„±
- ë¬¸ë²•/í‘œí˜„ (Grammar): ë¬¸ë²• ì •í™•ì„±, ì–´íœ˜ ë‹¤ì–‘ì„±
- ë°œìŒ (Pronunciation): ìŒì†Œ ì •í™•ì„±, ì–µì–‘, ê°•ì„¸
- ìœ ì°½ì„± (Fluency): ë§í•˜ê¸° ì†ë„, íœ´ì§€ íŒ¨í„´, ìì—°ìŠ¤ëŸ¬ì›€

ê° í•­ëª©ì„ 0-4ì ìœ¼ë¡œ í‰ê°€í•˜ê³ , ìŒì„± íŠ¹ì§•ì„ ì°¸ê³ í•˜ì—¬ êµ¬ì²´ì ì¸ í”¼ë“œë°±ì„ ì œê³µí•˜ì„¸ìš”."""

        # ì‚¬ìš©ì ì…ë ¥ êµ¬ì„±
        user_message = f"""í•™ìƒ ë‹µë³€:
{transcript}
"""

        # ìŒì„± íŠ¹ì§• ì¶”ê°€ (ìˆëŠ” ê²½ìš°)
        if include_audio_features and has_audio_features:
            audio_summary = row.get('audio_summary', '')
            if pd.notna(audio_summary):
                user_message += f"\n{audio_summary}\n"

        user_message += "\nìœ„ ì •ë³´ë¥¼ ì°¸ê³ í•˜ì—¬ í•™ìƒì˜ ë‹µë³€ì„ í‰ê°€í•´ì£¼ì„¸ìš”."

        # ëª¨ë¸ ì‘ë‹µ (Ground Truth)
        assistant_message = f"""í‰ê°€ ê²°ê³¼:

**ë‚´ìš© (Content): {content_score}/4.0**
- ì§ˆë¬¸ì— ëŒ€í•œ ì ì ˆí•œ ë‹µë³€ ì œì‹œ
- ë…¼ë¦¬ì  êµ¬ì¡°ì™€ ì „ê°œ

**ë¬¸ë²•/í‘œí˜„ (Grammar): {grammar_score}/4.0**
- ë¬¸ë²•ì  ì •í™•ì„±
- ì–´íœ˜ ì‚¬ìš© ë° ë‹¤ì–‘ì„±

**ë°œìŒ (Pronunciation):**
{pronunciation_feedback}

**ìœ ì°½ì„± (Fluency):**
{fluency_feedback}

**ì¢…í•© ì ìˆ˜: {total_score}/4.0**

**í”¼ë“œë°±:**
{feedback}
"""

        # ìŒì„± íŠ¹ì§• ê¸°ë°˜ í”¼ë“œë°± ì¶”ê°€
        if include_audio_features and has_audio_features:
            additional_feedback = []

            # ë§í•˜ê¸° ì†ë„
            if pd.notna(row.get('speech_rate')):
                speech_rate = float(row['speech_rate'])
                if speech_rate < 2:
                    additional_feedback.append("- ë§í•˜ê¸° ì†ë„ ê°œì„ : íœ´ì§€ë¥¼ ì¤„ì´ê³  ìì—°ìŠ¤ëŸ½ê²Œ ë§í•˜ì„¸ìš”")
                elif speech_rate > 5:
                    additional_feedback.append("- ë§í•˜ê¸° ì†ë„ ì¡°ì ˆ: ë„ˆë¬´ ë¹ ë¥´ë©´ ëª…í™•ì„±ì´ ë–¨ì–´ì§‘ë‹ˆë‹¤")

            # íœ´ì§€
            if pd.notna(row.get('pause_mean')):
                pause_mean = float(row['pause_mean'])
                if pause_mean > 1.0:
                    additional_feedback.append("- íœ´ì§€ ê°œì„ : ê¸´ ë©ˆì¶¤ì„ ì¤„ì´ê³  ìœ ì°½ì„±ì„ ë†’ì´ì„¸ìš”")

            # Pitch ë³€ë™
            if pd.notna(row.get('pitch_std')):
                pitch_std = float(row['pitch_std'])
                if pitch_std < 20:
                    additional_feedback.append("- ì–µì–‘ ê°œì„ : ë” í’ë¶€í•œ ì–µì–‘ìœ¼ë¡œ í‘œí˜„ë ¥ì„ ë†’ì´ì„¸ìš”")

            if additional_feedback:
                assistant_message += "\n**ìŒì„± íŠ¹ì§• ê¸°ë°˜ ê°œì„  ë°©í–¥:**\n" + "\n".join(additional_feedback)


        # OpenAI í˜•ì‹
        training_example = {
            "messages": [
                {"role": "system", "content": system_message},
                {"role": "user", "content": user_message},
                {"role": "assistant", "content": assistant_message}
            ]
        }

        training_data.append(training_example)

    # JSONLë¡œ ì €ì¥
    with open(output_path, 'w', encoding='utf-8') as f:
        for example in training_data:
            f.write(json.dumps(example, ensure_ascii=False) + '\n')

    print(f"âœ… {len(training_data)}ê°œì˜ í•™ìŠµ ë°ì´í„° ìƒì„± ì™„ë£Œ")
    print(f"ğŸ’¾ ì €ì¥ ìœ„ì¹˜: {output_path}\n")

    # í†µê³„
    print("ğŸ“Š ë°ì´í„° í†µê³„:")
    print(f"- ì´ ìƒ˜í”Œ: {len(training_data)}ê°œ")

    avg_length = sum(len(d['messages'][1]['content']) for d in training_data) / len(training_data)
    print(f"- í‰ê·  ì…ë ¥ ê¸¸ì´: {avg_length:.0f} ì")

    if include_audio_features and has_audio_features:
        print(f"- ìŒì„± íŠ¹ì§•: âœ… í¬í•¨ë¨")
    else:
        print(f"- ìŒì„± íŠ¹ì§•: âŒ ë¯¸í¬í•¨")

    print()

    if len(training_data) < 50:
        print(f"âš ï¸  ê¶Œì¥ ìƒ˜í”Œ ìˆ˜: 50ê°œ ì´ìƒ (í˜„ì¬: {len(training_data)}ê°œ)")
        print(f"   OpenAI íŒŒì¸íŠœë‹ì€ ìµœì†Œ 10ê°œë¶€í„° ê°€ëŠ¥í•˜ì§€ë§Œ, 50ê°œ ì´ìƒ ê¶Œì¥í•©ë‹ˆë‹¤.")
    else:
        print(f"âœ… ì¶©ë¶„í•œ ë°ì´í„°: OpenAI íŒŒì¸íŠœë‹ ê°€ëŠ¥")

    return training_data


def validate_training_data(jsonl_path: str):
    """OpenAI í˜•ì‹ ê²€ì¦"""

    with open(jsonl_path, 'r', encoding='utf-8') as f:
        data = [json.loads(line) for line in f]

    print(f"\nğŸ” ë°ì´í„° ê²€ì¦:")

    errors = []
    for idx, item in enumerate(data):
        if 'messages' not in item:
            errors.append(f"ìƒ˜í”Œ {idx}: 'messages' í‚¤ ì—†ìŒ")
            continue

        messages = item['messages']

        if len(messages) != 3:
            errors.append(f"ìƒ˜í”Œ {idx}: ë©”ì‹œì§€ ê°œìˆ˜ëŠ” 3ê°œì—¬ì•¼ í•¨ (í˜„ì¬: {len(messages)})")

        expected_roles = ['system', 'user', 'assistant']
        actual_roles = [msg.get('role') for msg in messages]
        if actual_roles != expected_roles:
            errors.append(f"ìƒ˜í”Œ {idx}: role ìˆœì„œ ì˜¤ë¥˜")

    if errors:
        print("âŒ ê²€ì¦ ì‹¤íŒ¨:")
        for error in errors[:5]:
            print(f"   - {error}")
        if len(errors) > 5:
            print(f"   ... ì™¸ {len(errors)-5}ê°œ")
    else:
        print("âœ… ëª¨ë“  ë°ì´í„°ê°€ OpenAI í˜•ì‹ì— ë§ìŠµë‹ˆë‹¤")

    # í† í° ìˆ˜ ì¶”ì •
    total_chars = sum(
        sum(len(msg['content']) for msg in item['messages'])
        for item in data
    )
    estimated_tokens = total_chars // 4

    print(f"\nğŸ“ˆ í† í° ì¶”ì •:")
    print(f"- ì´ ë¬¸ì ìˆ˜: {total_chars:,}")
    print(f"- ì¶”ì • í† í° ìˆ˜: {estimated_tokens:,}")
    print(f"- í‰ê·  í† í°/ìƒ˜í”Œ: {estimated_tokens//len(data):,}")

    # ë¹„ìš© ì¶”ì •
    training_cost = estimated_tokens / 1000 * 0.008
    print(f"\nğŸ’° ì˜ˆìƒ íŒŒì¸íŠœë‹ ë¹„ìš© (GPT-3.5-turbo):")
    print(f"- í•™ìŠµ ë¹„ìš©: ${training_cost:.2f}")
    print(f"- ì¶”ë¡  ë¹„ìš© (1000íšŒ): ~$10-20")


if __name__ == "__main__":
    import argparse

    parser = argparse.ArgumentParser(description='OpenAI íŒŒì¸íŠœë‹ ë°ì´í„° ì¤€ë¹„')
    parser.add_argument('--csv', type=str, required=True,
                        help='í”¼ë“œë°± CSV íŒŒì¼ (ìŒì„± íŠ¹ì§• í¬í•¨)')
    parser.add_argument('--output', type=str, default='openai_training_data.jsonl',
                        help='ì¶œë ¥ JSONL íŒŒì¼')
    parser.add_argument('--no_audio_features', action='store_true',
                        help='ìŒì„± íŠ¹ì§• ì œì™¸')

    args = parser.parse_args()

    if not Path(args.csv).exists():
        print(f"âŒ CSV íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {args.csv}")
        exit(1)

    # ë°ì´í„° ìƒì„±
    training_data = create_openai_training_data(
        csv_path=args.csv,
        output_path=args.output,
        include_audio_features=not args.no_audio_features
    )

    # ê²€ì¦
    validate_training_data(args.output)

    print("\n" + "="*60)
    print("ë‹¤ìŒ ë‹¨ê³„:")
    print("="*60)
    print(f"1. OpenAI íŒŒì¸íŠœë‹ ì‹¤í–‰:")
    print(f"   openai api fine_tunes.create -t {args.output} -m gpt-3.5-turbo")
    print(f"\n2. ë˜ëŠ” ì›¹ ì¸í„°í˜ì´ìŠ¤:")
    print(f"   https://platform.openai.com/finetune")
    print(f"   íŒŒì¼ ì—…ë¡œë“œ: {args.output}")
    print("="*60)
