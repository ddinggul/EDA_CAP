import pandas as pd
import json
from pathlib import Path

def convert_to_training_format(csv_path: str, output_path: str, format_type: str = "openai"):
    """
    CSV ë°ì´í„°ë¥¼ LLM íŒŒì¸íŠœë‹ í˜•ì‹ìœ¼ë¡œ ë³€í™˜

    Args:
        csv_path: ì…ë ¥ CSV íŒŒì¼ ê²½ë¡œ
        output_path: ì¶œë ¥ JSONL íŒŒì¼ ê²½ë¡œ
        format_type: 'openai', 'huggingface', 'gemini' ì¤‘ ì„ íƒ
    """
    df = pd.read_csv(csv_path)

    training_data = []

    for idx, row in df.iterrows():
        # ê¸°ë³¸ ì •ë³´ ì¶”ì¶œ
        text = row['í…ìŠ¤íŠ¸']
        feedback = row['í…ìŠ¤íŠ¸ í”¼ë“œë°±'] if pd.notna(row['í…ìŠ¤íŠ¸ í”¼ë“œë°±']) else ""
        pronunciation = row['ë°œìŒ'] if pd.notna(row['ë°œìŒ']) else ""
        fluency = row['fluency'] if pd.notna(row['fluency']) else ""
        content = row['ë‚´ìš©'] if pd.notna(row['ë‚´ìš©']) else ""
        grammar = row['ë¬¸ë²•/í‘œí˜„'] if pd.notna(row['ë¬¸ë²•/í‘œí˜„']) else ""
        total_score = row['total_score']

        # ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ êµ¬ì„±
        system_prompt = """ë‹¹ì‹ ì€ TOEFL ìŠ¤í”¼í‚¹ í‰ê°€ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. í•™ìƒì˜ ë‹µë³€ì„ ë‹¤ìŒ ê¸°ì¤€ìœ¼ë¡œ í‰ê°€í•˜ì„¸ìš”:

1. ë°œìŒ(Pronunciation): ê°œë³„ ìŒì†Œì˜ ì •í™•ì„±, R/L êµ¬ë¶„, ì¥ë‹¨ëª¨ìŒ êµ¬ë¶„
2. ìœ ì°½ì„±(Fluency): ë§í•˜ê¸° ì†ë„, í†¤ ì¡°ì ˆ, ê°•ì¡°, ìì—°ìŠ¤ëŸ¬ì›€
3. ë‚´ìš©(Content): ì§ˆë¬¸ì— ëŒ€í•œ ì ì ˆí•œ ë‹µë³€, ë…¼ë¦¬ì  êµ¬ì¡°
4. ë¬¸ë²•/í‘œí˜„(Grammar & Expression): ë¬¸ë²•ì  ì •í™•ì„±, ì ì ˆí•œ ì–´íœ˜ ì‚¬ìš©

ê° í•­ëª©ì— ëŒ€í•œ êµ¬ì²´ì ì¸ í”¼ë“œë°±ê³¼ í•¨ê»˜ ì´ì (0-4ì )ì„ ì œê³µí•˜ì„¸ìš”."""

        # ì‚¬ìš©ì ì…ë ¥ êµ¬ì„±
        user_input = f"ë‹¤ìŒ í•™ìƒì˜ ë‹µë³€ì„ í‰ê°€í•´ì£¼ì„¸ìš”:\n\n{text}"

        # ëª¨ë¸ ì‘ë‹µ êµ¬ì„± (Ground Truth)
        assistant_response = f"""í‰ê°€ ê²°ê³¼:

**ë°œìŒ (Pronunciation):**
{pronunciation if pronunciation else 'í‰ê°€ ë‚´ìš© ì—†ìŒ'}

**ìœ ì°½ì„± (Fluency):**
{fluency if fluency else 'í‰ê°€ ë‚´ìš© ì—†ìŒ'}

**ë‚´ìš© (Content):**
{content if content else 'í‰ê°€ ë‚´ìš© ì—†ìŒ'}

**ë¬¸ë²•/í‘œí˜„ (Grammar & Expression):**
{grammar if grammar else 'í‰ê°€ ë‚´ìš© ì—†ìŒ'}

**ì¶”ê°€ í”¼ë“œë°±:**
{feedback if feedback else 'ì—†ìŒ'}

**ì´ì : {total_score}/4.0**"""

        # í˜•ì‹ì— ë§ê²Œ ë³€í™˜
        if format_type == "openai":
            # OpenAI Fine-tuning í˜•ì‹ (GPT-3.5, GPT-4)
            training_example = {
                "messages": [
                    {"role": "system", "content": system_prompt},
                    {"role": "user", "content": user_input},
                    {"role": "assistant", "content": assistant_response}
                ]
            }
        elif format_type == "huggingface":
            # HuggingFace í˜•ì‹
            training_example = {
                "text": f"<|system|>\n{system_prompt}\n<|user|>\n{user_input}\n<|assistant|>\n{assistant_response}"
            }
        elif format_type == "gemini":
            # Google Gemini í˜•ì‹
            training_example = {
                "contents": [
                    {"role": "user", "parts": [{"text": user_input}]},
                    {"role": "model", "parts": [{"text": assistant_response}]}
                ],
                "system_instruction": {"parts": [{"text": system_prompt}]}
            }
        else:
            raise ValueError(f"Unknown format type: {format_type}")

        training_data.append(training_example)

    # JSONL í˜•ì‹ìœ¼ë¡œ ì €ì¥
    with open(output_path, 'w', encoding='utf-8') as f:
        for example in training_data:
            f.write(json.dumps(example, ensure_ascii=False) + '\n')

    print(f"âœ… {len(training_data)}ê°œì˜ í•™ìŠµ ë°ì´í„°ë¥¼ {output_path}ì— ì €ì¥í–ˆìŠµë‹ˆë‹¤.")
    return training_data


def validate_training_data(jsonl_path: str):
    """í•™ìŠµ ë°ì´í„°ì˜ í’ˆì§ˆ ê²€ì¦"""
    with open(jsonl_path, 'r', encoding='utf-8') as f:
        data = [json.loads(line) for line in f]

    print(f"\nğŸ“Š ë°ì´í„° í†µê³„:")
    print(f"ì´ ìƒ˜í”Œ ìˆ˜: {len(data)}")

    # í† í° ê¸¸ì´ ë¶„ì„ (ê°„ë‹¨í•œ ì¶”ì •)
    total_tokens = 0
    for item in data:
        if 'messages' in item:
            for msg in item['messages']:
                total_tokens += len(msg['content'].split())

    avg_tokens = total_tokens / len(data) if data else 0
    print(f"í‰ê·  í† í° ìˆ˜ (ì¶”ì •): {avg_tokens:.1f}")
    print(f"\nê¶Œì¥ì‚¬í•­:")
    print(f"- ìµœì†Œ í•™ìŠµ ë°ì´í„°: 50-100ê°œ")
    print(f"- í˜„ì¬ ë°ì´í„°: {len(data)}ê°œ")

    if len(data) < 50:
        print(f"âš ï¸  ë°ì´í„°ê°€ ë¶€ì¡±í•©ë‹ˆë‹¤. ë” ë§ì€ í‰ê°€ ìƒ˜í”Œì„ ìˆ˜ì§‘í•˜ì„¸ìš”.")
    else:
        print(f"âœ… ì¶©ë¶„í•œ ë°ì´í„°ê°€ ìˆìŠµë‹ˆë‹¤.")


if __name__ == "__main__":
    # ì˜ˆì‹œ ì‹¤í–‰
    print("TOEFL ìŠ¤í”¼í‚¹ í‰ê°€ íŒŒì¸íŠœë‹ ë°ì´í„° ì¤€ë¹„ ë„êµ¬\n")

    # CSV íŒŒì¼ ê²½ë¡œ ì„¤ì •
    csv_file = "toefl_evaluations.csv"

    if not Path(csv_file).exists():
        print(f"âŒ {csv_file} íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        print("CSV íŒŒì¼ì„ ë¨¼ì € ì¤€ë¹„í•´ì£¼ì„¸ìš”.")
    else:
        # ì—¬ëŸ¬ í˜•ì‹ìœ¼ë¡œ ë³€í™˜
        print("ë³€í™˜í•  í˜•ì‹ì„ ì„ íƒí•˜ì„¸ìš”:")
        print("1. OpenAI (GPT-3.5/GPT-4)")
        print("2. HuggingFace (Llama, Mistral ë“±)")
        print("3. Google Gemini")

        choice = input("\nì„ íƒ (1-3): ").strip()

        format_map = {
            "1": "openai",
            "2": "huggingface",
            "3": "gemini"
        }

        format_type = format_map.get(choice, "openai")
        output_file = f"training_data_{format_type}.jsonl"

        training_data = convert_to_training_format(csv_file, output_file, format_type)
        validate_training_data(output_file)
