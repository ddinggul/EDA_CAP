"""
ìŒì„± íŒŒì¼ì—ì„œ MFCC íŠ¹ì§• ì¶”ì¶œ í›„ CSVì— ì¶”ê°€
OpenAI GPT íŒŒì¸íŠœë‹ì— ìŒì„± íŠ¹ì§• ì •ë³´ í¬í•¨
"""

import librosa
import numpy as np
import pandas as pd
from pathlib import Path
from typing import Dict, List
import json


def extract_mfcc_features(audio_path: str, sr: int = 16000, n_mfcc: int = 13) -> Dict:
    """
    ìŒì„± íŒŒì¼ì—ì„œ MFCC ë° ì£¼ìš” íŠ¹ì§• ì¶”ì¶œ

    Args:
        audio_path: WAV íŒŒì¼ ê²½ë¡œ
        sr: ìƒ˜í”Œë§ ë ˆì´íŠ¸
        n_mfcc: MFCC ê³„ìˆ˜ ê°œìˆ˜

    Returns:
        ìŒì„± íŠ¹ì§• ë”•ì…”ë„ˆë¦¬
    """

    # ì˜¤ë””ì˜¤ ë¡œë“œ
    y, sr = librosa.load(audio_path, sr=sr)

    # 1. MFCC ì¶”ì¶œ
    mfcc = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=n_mfcc)
    mfcc_mean = np.mean(mfcc, axis=1)
    mfcc_std = np.std(mfcc, axis=1)

    # 2. Pitch (F0) ì¶”ì¶œ
    pitches, magnitudes = librosa.piptrack(y=y, sr=sr)
    pitch_values = []
    for t in range(pitches.shape[1]):
        index = magnitudes[:, t].argmax()
        pitch = pitches[index, t]
        if pitch > 0:
            pitch_values.append(pitch)

    pitch_mean = np.mean(pitch_values) if pitch_values else 0
    pitch_std = np.std(pitch_values) if pitch_values else 0

    # 3. Energy (RMS)
    energy = librosa.feature.rms(y=y)[0]
    energy_mean = float(np.mean(energy))
    energy_std = float(np.std(energy))

    # 4. Zero Crossing Rate (ìŒì„±/ë¬´ìŒ êµ¬ë¶„)
    zcr = librosa.feature.zero_crossing_rate(y)[0]
    zcr_mean = float(np.mean(zcr))

    # 5. Spectral Centroid (ìŒìƒ‰)
    spectral_centroid = librosa.feature.spectral_centroid(y=y, sr=sr)[0]
    spectral_centroid_mean = float(np.mean(spectral_centroid))

    # 6. Tempo (ë§í•˜ê¸° ì†ë„)
    onset_env = librosa.onset.onset_strength(y=y, sr=sr)
    tempo = librosa.beat.tempo(onset_envelope=onset_env, sr=sr)[0]

    # 7. ìŒì„± ê¸¸ì´
    duration = float(librosa.get_duration(y=y, sr=sr))

    # 8. ë¬´ìŒ êµ¬ê°„ íƒì§€ (íœ´ì§€)
    intervals = librosa.effects.split(y, top_db=30)
    num_pauses = len(intervals) - 1

    pauses = []
    for i in range(len(intervals) - 1):
        pause_duration = (intervals[i + 1][0] - intervals[i][1]) / sr
        pauses.append(pause_duration)

    pause_mean = float(np.mean(pauses)) if pauses else 0
    pause_total = float(np.sum(pauses)) if pauses else 0

    # íŠ¹ì§• ìš”ì•½
    features = {
        # MFCC í†µê³„
        'mfcc_mean_0': float(mfcc_mean[0]),
        'mfcc_mean_1': float(mfcc_mean[1]),
        'mfcc_mean_2': float(mfcc_mean[2]),
        'mfcc_std_0': float(mfcc_std[0]),
        'mfcc_std_1': float(mfcc_std[1]),

        # Pitch (ìŒë†’ì´)
        'pitch_mean': float(pitch_mean),
        'pitch_std': float(pitch_std),

        # Energy (ìŒëŸ‰)
        'energy_mean': energy_mean,
        'energy_std': energy_std,

        # ê¸°íƒ€
        'zcr_mean': zcr_mean,
        'spectral_centroid_mean': spectral_centroid_mean,
        'tempo': float(tempo),

        # ìœ ì°½ì„± ê´€ë ¨
        'duration': duration,
        'num_pauses': num_pauses,
        'pause_mean': pause_mean,
        'pause_total': pause_total,
        'speech_rate': num_pauses / duration if duration > 0 else 0
    }

    return features


def create_text_summary(features: Dict) -> str:
    """
    ìŒì„± íŠ¹ì§•ì„ í…ìŠ¤íŠ¸ë¡œ ìš”ì•½ (GPTì—ê²Œ ì „ë‹¬í•  í˜•ì‹)

    Args:
        features: ìŒì„± íŠ¹ì§• ë”•ì…”ë„ˆë¦¬

    Returns:
        í…ìŠ¤íŠ¸ ìš”ì•½
    """

    summary = f"""ìŒì„± íŠ¹ì§• ë¶„ì„:
- ê¸¸ì´: {features['duration']:.1f}ì´ˆ
- ë§í•˜ê¸° ì†ë„: {features['speech_rate']:.2f} êµ¬ê°„/ì´ˆ
- í‰ê·  Pitch: {features['pitch_mean']:.1f}Hz (ë³€ë™: {features['pitch_std']:.1f})
- í‰ê·  Energy: {features['energy_mean']:.3f} (ì•ˆì •ì„±: {features['energy_std']:.3f})
- íœ´ì§€(Pause): {features['num_pauses']}íšŒ, í‰ê·  {features['pause_mean']:.2f}ì´ˆ
- MFCC[0-2]: [{features['mfcc_mean_0']:.2f}, {features['mfcc_mean_1']:.2f}, {features['mfcc_mean_2']:.2f}]
"""

    # íŠ¹ì§• í•´ì„ ì¶”ê°€
    interpretations = []

    # ë§í•˜ê¸° ì†ë„
    if features['speech_rate'] < 2:
        interpretations.append("- ë§í•˜ê¸° ì†ë„ê°€ ëŠë¦¼ (íœ´ì§€ ë§ìŒ)")
    elif features['speech_rate'] > 5:
        interpretations.append("- ë§í•˜ê¸° ì†ë„ê°€ ë¹ ë¦„ (ìœ ì°½í•¨)")

    # íœ´ì§€
    if features['pause_mean'] > 1.0:
        interpretations.append("- ê¸´ íœ´ì§€ â†’ ë§ë”ë“¬ ë˜ëŠ” ìƒê°í•˜ëŠ” ì‹œê°„ ë§ìŒ")

    # Pitch ë³€ë™
    if features['pitch_std'] < 20:
        interpretations.append("- Pitch ë³€ë™ ì ìŒ â†’ ë‹¨ì¡°ë¡œìš´ ì–µì–‘")
    elif features['pitch_std'] > 50:
        interpretations.append("- Pitch ë³€ë™ ë§ìŒ â†’ í’ë¶€í•œ ì–µì–‘")

    if interpretations:
        summary += "\níŠ¹ì§• í•´ì„:\n" + "\n".join(interpretations)

    return summary


def process_audio_files_to_csv(
    audio_dir: str,
    csv_path: str,
    output_csv: str = "feedback_with_features.csv"
):
    """
    ìŒì„± íŒŒì¼ë“¤ì˜ íŠ¹ì§•ì„ ì¶”ì¶œí•˜ì—¬ CSVì— ì¶”ê°€

    Args:
        audio_dir: WAV íŒŒì¼ ë””ë ‰í† ë¦¬
        csv_path: ê¸°ì¡´ í”¼ë“œë°± CSV
        output_csv: ì¶œë ¥ CSV íŒŒì¼
    """

    print("=" * 60)
    print("ğŸ¤ ìŒì„± íŠ¹ì§• ì¶”ì¶œ ë° CSV í†µí•©")
    print("=" * 60)
    print()

    # ê¸°ì¡´ CSV ë¡œë“œ
    df = pd.read_csv(csv_path)
    print(f"ğŸ“Š ê¸°ì¡´ CSV ë¡œë“œ: {len(df)}ê°œ í–‰")

    # ìŒì„± íŒŒì¼ ëª©ë¡
    audio_files = list(Path(audio_dir).glob("*.wav"))
    print(f"ğŸµ WAV íŒŒì¼: {len(audio_files)}ê°œ")
    print()

    # ìƒˆ ì»¬ëŸ¼ë“¤ ì¤€ë¹„
    feature_columns = [
        'audio_duration', 'pitch_mean', 'pitch_std',
        'energy_mean', 'num_pauses', 'pause_mean',
        'speech_rate', 'audio_summary'
    ]

    # ê¸°ì¡´ ì»¬ëŸ¼ì— ì—†ìœ¼ë©´ ì¶”ê°€
    for col in feature_columns:
        if col not in df.columns:
            df[col] = None

    # ê° ìŒì„± íŒŒì¼ ì²˜ë¦¬
    matched_count = 0

    for i, audio_file in enumerate(audio_files):
        print(f"[{i+1}/{len(audio_files)}] {audio_file.name}")

        try:
            # íŠ¹ì§• ì¶”ì¶œ
            features = extract_mfcc_features(str(audio_file))

            # í…ìŠ¤íŠ¸ ìš”ì•½ ìƒì„±
            text_summary = create_text_summary(features)

            # íŒŒì¼ëª…ìœ¼ë¡œ CSV ë§¤ì¹­
            file_id = audio_file.stem
            matching_rows = df[df['íŒŒì¼ ì´ë¦„'].str.contains(file_id, na=False)]

            if not matching_rows.empty:
                idx = matching_rows.index[0]

                # CSVì— íŠ¹ì§• ì¶”ê°€
                df.at[idx, 'audio_duration'] = features['duration']
                df.at[idx, 'pitch_mean'] = features['pitch_mean']
                df.at[idx, 'pitch_std'] = features['pitch_std']
                df.at[idx, 'energy_mean'] = features['energy_mean']
                df.at[idx, 'num_pauses'] = features['num_pauses']
                df.at[idx, 'pause_mean'] = features['pause_mean']
                df.at[idx, 'speech_rate'] = features['speech_rate']
                df.at[idx, 'audio_summary'] = text_summary

                matched_count += 1
                print(f"   âœ… ë§¤ì¹­ë¨: {df.at[idx, 'íŒŒì¼ ì´ë¦„']}")
                print(f"   ê¸¸ì´: {features['duration']:.1f}ì´ˆ, "
                      f"Pitch: {features['pitch_mean']:.1f}Hz, "
                      f"íœ´ì§€: {features['num_pauses']}íšŒ")
            else:
                print(f"   âš ï¸  CSVì—ì„œ ë§¤ì¹­ ì‹¤íŒ¨: {file_id}")

        except Exception as e:
            print(f"   âŒ ì˜¤ë¥˜: {e}")
            continue

        print()

    # CSV ì €ì¥
    df.to_csv(output_csv, index=False, encoding='utf-8-sig')

    print("=" * 60)
    print("âœ… ì™„ë£Œ!")
    print("=" * 60)
    print(f"ì´ {len(audio_files)}ê°œ íŒŒì¼ ì¤‘ {matched_count}ê°œ ë§¤ì¹­")
    print(f"ğŸ’¾ ì €ì¥: {output_csv}")
    print()

    # í†µê³„
    print("ğŸ“Š ì¶”ì¶œëœ íŠ¹ì§• í†µê³„:")
    if matched_count > 0:
        print(f"  í‰ê·  ê¸¸ì´: {df['audio_duration'].mean():.1f}ì´ˆ")
        print(f"  í‰ê·  Pitch: {df['pitch_mean'].mean():.1f}Hz")
        print(f"  í‰ê·  íœ´ì§€ íšŸìˆ˜: {df['num_pauses'].mean():.1f}íšŒ")
        print(f"  í‰ê·  ë§í•˜ê¸° ì†ë„: {df['speech_rate'].mean():.2f} êµ¬ê°„/ì´ˆ")

    return output_csv


if __name__ == "__main__":
    import argparse

    parser = argparse.ArgumentParser(description='ìŒì„± íŠ¹ì§• ì¶”ì¶œ ë° CSV í†µí•©')
    parser.add_argument('--audio_dir', type=str, required=True,
                        help='WAV íŒŒì¼ ë””ë ‰í† ë¦¬')
    parser.add_argument('--csv', type=str, required=True,
                        help='ê¸°ì¡´ í”¼ë“œë°± CSV')
    parser.add_argument('--output', type=str, default='feedback_with_features.csv',
                        help='ì¶œë ¥ CSV íŒŒì¼')

    args = parser.parse_args()

    if not Path(args.audio_dir).exists():
        print(f"âŒ ë””ë ‰í† ë¦¬ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {args.audio_dir}")
        exit(1)

    if not Path(args.csv).exists():
        print(f"âŒ CSV íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {args.csv}")
        exit(1)

    # ì‹¤í–‰
    output_csv = process_audio_files_to_csv(
        audio_dir=args.audio_dir,
        csv_path=args.csv,
        output_csv=args.output
    )

    print("\në‹¤ìŒ ë‹¨ê³„:")
    print("="*60)
    print("1. ìƒì„±ëœ CSV í™•ì¸:")
    print(f"   cat {output_csv}")
    print()
    print("2. OpenAI íŒŒì¸íŠœë‹ ë°ì´í„° ìƒì„±:")
    print(f"   python prepare_openai_finetuning.py --csv {output_csv}")
    print("="*60)
