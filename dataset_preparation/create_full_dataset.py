"""
ì „ì²´ ë°ì´í„°ì…‹ ì¤€ë¹„ íŒŒì´í”„ë¼ì¸
ìŒì„± íŠ¹ì§• ì¶”ì¶œ + ìŒì„± ëª¨ë¸ í•™ìŠµ + LLM ë°ì´í„° ì¤€ë¹„ë¥¼ í•œ ë²ˆì— ì‹¤í–‰
"""

import argparse
import json
from pathlib import Path
import sys

# ìƒìœ„ í´ë”ë¥¼ import pathì— ì¶”ê°€
sys.path.append(str(Path(__file__).parent))

from audio_feature_extraction import process_audio_dataset, create_feature_summary
from train_audio_model import train_audio_model
from prepare_training_data import convert_to_training_format, validate_training_data


def create_full_dataset(
    audio_dir: str,
    csv_path: str,
    output_dir: str = "../processed_data",
    train_audio_model_flag: bool = True,
    prepare_llm_data: bool = True,
    audio_model_epochs: int = 100,
    llm_format: str = "huggingface"
):
    """
    ì „ì²´ ë°ì´í„°ì…‹ ì¤€ë¹„ íŒŒì´í”„ë¼ì¸

    Args:
        audio_dir: WAV íŒŒì¼ ë””ë ‰í† ë¦¬
        csv_path: í”¼ë“œë°± CSV íŒŒì¼
        output_dir: ì¶œë ¥ ë””ë ‰í† ë¦¬
        train_audio_model_flag: ìŒì„± ëª¨ë¸ í•™ìŠµ ì—¬ë¶€
        prepare_llm_data: LLM ë°ì´í„° ì¤€ë¹„ ì—¬ë¶€
        audio_model_epochs: ìŒì„± ëª¨ë¸ í•™ìŠµ ì—í¬í¬
        llm_format: LLM ë°ì´í„° í˜•ì‹ (openai/huggingface/gemini)
    """

    output_path = Path(output_dir)
    output_path.mkdir(parents=True, exist_ok=True)

    print("=" * 80)
    print("ğŸ“ TOEFL ìŠ¤í”¼í‚¹ í‰ê°€ ë°ì´í„°ì…‹ ì¤€ë¹„ íŒŒì´í”„ë¼ì¸")
    print("=" * 80)
    print(f"ìŒì„± ë””ë ‰í† ë¦¬: {audio_dir}")
    print(f"CSV íŒŒì¼: {csv_path}")
    print(f"ì¶œë ¥ ë””ë ‰í† ë¦¬: {output_dir}")
    print("=" * 80)
    print()

    # ===================================================================
    # 1ë‹¨ê³„: ìŒì„± íŠ¹ì§• ì¶”ì¶œ
    # ===================================================================
    print("ğŸ“Š [1/3] ìŒì„± íŠ¹ì§• ì¶”ì¶œ")
    print("-" * 80)

    audio_features_path = output_path / "audio_features.jsonl"

    if not audio_features_path.exists():
        print("ğŸ¤ ìŒì„± íŒŒì¼ ì²˜ë¦¬ ì‹œì‘...")

        results = process_audio_dataset(
            audio_dir=audio_dir,
            csv_path=csv_path,
            output_path=str(audio_features_path)
        )

        print()
        create_feature_summary(str(audio_features_path))
        print()
    else:
        print(f"âœ… ìŒì„± íŠ¹ì§• íŒŒì¼ì´ ì´ë¯¸ ì¡´ì¬í•©ë‹ˆë‹¤: {audio_features_path}")
        print("   (ì‚­ì œ í›„ ë‹¤ì‹œ ì‹¤í–‰í•˜ë©´ ì¬ìƒì„±ë©ë‹ˆë‹¤)")
        print()

    # ===================================================================
    # 2ë‹¨ê³„: ìŒì„± ëª¨ë¸ í•™ìŠµ (ì„ íƒ)
    # ===================================================================
    if train_audio_model_flag:
        print("ğŸ“Š [2/3] ìŒì„± í‰ê°€ ëª¨ë¸ í•™ìŠµ (LSTM)")
        print("-" * 80)

        audio_model_dir = output_path / "audio_model"

        if not (audio_model_dir / "best_model.pth").exists():
            print("ğŸ§  LSTM ëª¨ë¸ í•™ìŠµ ì‹œì‘...")

            train_audio_model(
                jsonl_path=str(audio_features_path),
                output_dir=str(audio_model_dir),
                epochs=audio_model_epochs,
                batch_size=32,
                learning_rate=0.001
            )
            print()
        else:
            print(f"âœ… ìŒì„± ëª¨ë¸ì´ ì´ë¯¸ ì¡´ì¬í•©ë‹ˆë‹¤: {audio_model_dir}")
            print("   (í´ë” ì‚­ì œ í›„ ë‹¤ì‹œ ì‹¤í–‰í•˜ë©´ ì¬í•™ìŠµë©ë‹ˆë‹¤)")
            print()
    else:
        print("â­ï¸  [2/3] ìŒì„± ëª¨ë¸ í•™ìŠµ ê±´ë„ˆë›°ê¸°")
        print()

    # ===================================================================
    # 3ë‹¨ê³„: LLM íŒŒì¸íŠœë‹ ë°ì´í„° ì¤€ë¹„ (ì„ íƒ)
    # ===================================================================
    if prepare_llm_data:
        print("ğŸ“Š [3/3] LLM íŒŒì¸íŠœë‹ ë°ì´í„° ì¤€ë¹„")
        print("-" * 80)

        llm_data_path = output_path / f"training_data_{llm_format}.jsonl"

        if not llm_data_path.exists():
            print(f"ğŸ“ LLM ë°ì´í„° ìƒì„± ì¤‘ ({llm_format} í˜•ì‹)...")

            # CSVì—ì„œ LLM ë°ì´í„° ìƒì„±
            convert_to_training_format(
                csv_path=csv_path,
                output_path=str(llm_data_path),
                format_type=llm_format
            )

            print()
            validate_training_data(str(llm_data_path))
            print()
        else:
            print(f"âœ… LLM ë°ì´í„°ê°€ ì´ë¯¸ ì¡´ì¬í•©ë‹ˆë‹¤: {llm_data_path}")
            print("   (ì‚­ì œ í›„ ë‹¤ì‹œ ì‹¤í–‰í•˜ë©´ ì¬ìƒì„±ë©ë‹ˆë‹¤)")
            print()
    else:
        print("â­ï¸  [3/3] LLM ë°ì´í„° ì¤€ë¹„ ê±´ë„ˆë›°ê¸°")
        print()

    # ===================================================================
    # ì™„ë£Œ ìš”ì•½
    # ===================================================================
    print("=" * 80)
    print("âœ… ë°ì´í„°ì…‹ ì¤€ë¹„ ì™„ë£Œ!")
    print("=" * 80)
    print()
    print("ğŸ“ ìƒì„±ëœ íŒŒì¼:")
    print(f"   1. ìŒì„± íŠ¹ì§•: {audio_features_path}")

    if train_audio_model_flag:
        audio_model_dir = output_path / "audio_model"
        print(f"   2. ìŒì„± ëª¨ë¸: {audio_model_dir}/")
        print(f"      - best_model.pth (LSTM ëª¨ë¸)")
        print(f"      - scaler.pkl (ì •ê·œí™” ìŠ¤ì¼€ì¼ëŸ¬)")
        print(f"      - metadata.json (ë©”íƒ€ì •ë³´)")

    if prepare_llm_data:
        llm_data_path = output_path / f"training_data_{llm_format}.jsonl"
        print(f"   3. LLM ë°ì´í„°: {llm_data_path}")

    print()
    print("ğŸ“Œ ë‹¤ìŒ ë‹¨ê³„:")

    if train_audio_model_flag:
        print("   âœ… ìŒì„± ëª¨ë¸ í•™ìŠµ ì™„ë£Œ - ë°”ë¡œ ì‚¬ìš© ê°€ëŠ¥!")
    else:
        print("   â¡ï¸  ìŒì„± ëª¨ë¸ í•™ìŠµ:")
        print(f"      python train_audio_model.py --data {audio_features_path}")

    if prepare_llm_data:
        print()
        print("   â¡ï¸  LLM íŒŒì¸íŠœë‹:")
        if llm_format == "huggingface":
            print("      python ../finetune_huggingface.py")
            print("      ë˜ëŠ” python ../finetune_m2_mac.py (M2 Mac)")
        elif llm_format == "openai":
            print("      python ../finetune_openai.py")

    print()
    print("   â¡ï¸  í†µí•© í‰ê°€:")
    print("      python ../integrated_evaluation_system.py \\")
    print("        --audio student.wav \\")
    print("        --transcript 'text...' \\")
    print(f"        --audio_model {output_path / 'audio_model'}")

    print()
    print("=" * 80)


def main():
    parser = argparse.ArgumentParser(
        description='TOEFL í‰ê°€ ë°ì´í„°ì…‹ ì „ì²´ ì¤€ë¹„ íŒŒì´í”„ë¼ì¸',
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ì˜ˆì‹œ:
  # ì „ì²´ ìë™ ì‹¤í–‰ (ìŒì„± ëª¨ë¸ í•™ìŠµ í¬í•¨)
  python create_full_dataset.py \\
    --audio_dir ../audio \\
    --csv ../feedback.csv \\
    --train_audio_model

  # ìŒì„± íŠ¹ì§•ë§Œ ì¶”ì¶œ
  python create_full_dataset.py \\
    --audio_dir ../audio \\
    --csv ../feedback.csv \\
    --no_train_audio \\
    --no_llm_data

  # LLM ë°ì´í„°ë§Œ ì¤€ë¹„
  python create_full_dataset.py \\
    --csv ../feedback.csv \\
    --only_llm_data \\
    --llm_format openai
        """
    )

    parser.add_argument('--audio_dir', type=str,
                        help='WAV íŒŒì¼ ë””ë ‰í† ë¦¬')
    parser.add_argument('--csv', type=str, required=True,
                        help='í”¼ë“œë°± CSV íŒŒì¼')
    parser.add_argument('--output_dir', type=str, default='../processed_data',
                        help='ì¶œë ¥ ë””ë ‰í† ë¦¬ (ê¸°ë³¸: ../processed_data)')

    # ìŒì„± ëª¨ë¸ ì˜µì…˜
    parser.add_argument('--train_audio_model', action='store_true',
                        help='ìŒì„± ëª¨ë¸ í•™ìŠµ ì‹¤í–‰')
    parser.add_argument('--no_train_audio', action='store_true',
                        help='ìŒì„± ëª¨ë¸ í•™ìŠµ ê±´ë„ˆë›°ê¸°')
    parser.add_argument('--audio_epochs', type=int, default=100,
                        help='ìŒì„± ëª¨ë¸ í•™ìŠµ ì—í¬í¬ (ê¸°ë³¸: 100)')

    # LLM ë°ì´í„° ì˜µì…˜
    parser.add_argument('--llm_format', type=str,
                        choices=['openai', 'huggingface', 'gemini'],
                        default='huggingface',
                        help='LLM ë°ì´í„° í˜•ì‹ (ê¸°ë³¸: huggingface)')
    parser.add_argument('--no_llm_data', action='store_true',
                        help='LLM ë°ì´í„° ì¤€ë¹„ ê±´ë„ˆë›°ê¸°')

    # íŠ¹ìˆ˜ ëª¨ë“œ
    parser.add_argument('--only_llm_data', action='store_true',
                        help='LLM ë°ì´í„°ë§Œ ì¤€ë¹„ (ìŒì„± ì²˜ë¦¬ ê±´ë„ˆë›°ê¸°)')

    args = parser.parse_args()

    # ê²€ì¦
    if not args.only_llm_data and not args.audio_dir:
        parser.error("--audio_dirì´ í•„ìš”í•©ë‹ˆë‹¤. (ë˜ëŠ” --only_llm_data ì‚¬ìš©)")

    if not Path(args.csv).exists():
        print(f"âŒ CSV íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {args.csv}")
        sys.exit(1)

    if not args.only_llm_data and not Path(args.audio_dir).exists():
        print(f"âŒ ìŒì„± ë””ë ‰í† ë¦¬ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {args.audio_dir}")
        sys.exit(1)

    # ì‹¤í–‰
    if args.only_llm_data:
        # LLM ë°ì´í„°ë§Œ
        print("ğŸ“ LLM ë°ì´í„°ë§Œ ì¤€ë¹„í•©ë‹ˆë‹¤...")
        output_path = Path(args.output_dir)
        output_path.mkdir(parents=True, exist_ok=True)

        llm_data_path = output_path / f"training_data_{args.llm_format}.jsonl"
        convert_to_training_format(
            csv_path=args.csv,
            output_path=str(llm_data_path),
            format_type=args.llm_format
        )
        validate_training_data(str(llm_data_path))
    else:
        # ì „ì²´ íŒŒì´í”„ë¼ì¸
        create_full_dataset(
            audio_dir=args.audio_dir,
            csv_path=args.csv,
            output_dir=args.output_dir,
            train_audio_model_flag=args.train_audio_model and not args.no_train_audio,
            prepare_llm_data=not args.no_llm_data,
            audio_model_epochs=args.audio_epochs,
            llm_format=args.llm_format
        )


if __name__ == "__main__":
    main()
