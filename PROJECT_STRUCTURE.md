# π“ ν”„λ΅μ νΈ κµ¬μ΅°

TOEFL μ¤ν”Όν‚Ή ν‰κ°€ μ‹μ¤ν… - μ „μ²΄ νμΌ κµ¬μ΅° λ° μ‚¬μ© κ°€μ΄λ“

---

## π—‚οΈ ν΄λ” κµ¬μ΅°

```
EDA_CAP/
β”‚
β”β”€β”€ π“‚ dataset_preparation/          # λ°μ΄ν„°μ…‹ μ¤€λΉ„ λ„κµ¬ β­
β”‚   β”β”€β”€ README.md                    # λ°μ΄ν„°μ…‹ μ¤€λΉ„ κ°€μ΄λ“
β”‚   β”β”€β”€ audio_feature_extraction.py  # μμ„± νΉμ§• μ¶”μ¶ (MFCC, Pitch λ“±)
β”‚   β”β”€β”€ train_audio_model.py         # μμ„± ν‰κ°€ λ¨λΈ ν•™μµ (LSTM)
β”‚   β”β”€β”€ prepare_training_data.py     # LLM νμΈνλ‹ λ°μ΄ν„° λ³€ν™
β”‚   β””β”€β”€ create_full_dataset.py       # μ „μ²΄ νμ΄ν”„λΌμΈ ν†µν•© μ¤ν¬λ¦½νΈ
β”‚
β”β”€β”€ π“‚ models/                       # ν•™μµλ λ¨λΈ μ €μ¥ (μƒμ„±λ¨)
β”‚   β”β”€β”€ audio_model/                 # LSTM λ°μ/μ μ°½μ„± λ¨λΈ
β”‚   β””β”€β”€ toefl_finetuned_mlx/         # νμΈνλ‹λ LLM
β”‚
β”β”€β”€ π“‚ processed_data/               # μ²λ¦¬λ λ°μ΄ν„° (μƒμ„±λ¨)
β”‚   β”β”€β”€ audio_features.jsonl         # μμ„± νΉμ§•
β”‚   β””β”€β”€ training_data_*.jsonl        # LLM ν•™μµ λ°μ΄ν„°
β”‚
β”β”€β”€ π“ νμΈνλ‹ μ¤ν¬λ¦½νΈ
β”‚   β”β”€β”€ finetune_m2_mac.py          # M2 Mac μµμ ν™” νμΈνλ‹ (MLX)
β”‚   β”β”€β”€ finetune_huggingface.py     # HuggingFace λ¨λΈ νμΈνλ‹ (GPU)
β”‚   β””β”€β”€ finetune_openai.py          # OpenAI GPT νμΈνλ‹
β”‚
β”β”€β”€ π€ μ‹¤ν–‰ μ¤ν¬λ¦½νΈ
β”‚   β”β”€β”€ integrated_evaluation_system.py  # ν†µν•© ν‰κ°€ μ‹μ¤ν… β­β­β­
β”‚   β”β”€β”€ api_server_mlx.py                # REST API μ„λ²„
β”‚   β””β”€β”€ setup_m2.sh                      # M2 Mac μλ™ μ„¤μΉ
β”‚
β”β”€β”€ π“– κ°€μ΄λ“ λ¬Έμ„
β”‚   β”β”€β”€ QUICKSTART_M2.md            # π€ 5λ¶„ λΉ λ¥Έ μ‹μ‘
β”‚   β”β”€β”€ M2_MAC_SETUP.md             # M2 Mac μƒμ„Έ κ°€μ΄λ“
β”‚   β”β”€β”€ AUDIO_MULTIMODAL_GUIDE.md   # μμ„± κΈ°λ° ν‰κ°€ κ°€μ΄λ“
β”‚   β”β”€β”€ FINETUNING_GUIDE.md         # νμΈνλ‹ μ΄λ΅  λ° κ°€μ΄λ“
β”‚   β”β”€β”€ PROJECT_STRUCTURE.md        # μ΄ νμΌ
β”‚   β””β”€β”€ README_TOEFL_FINETUNING.md  # ν”„λ΅μ νΈ κ°μ”
β”‚
β”β”€β”€ β™οΈ μ„¤μ • νμΌ
β”‚   β”β”€β”€ requirements_m2.txt         # M2 Mac ν¨ν‚¤μ§€
β”‚   β”β”€β”€ requirements_audio.txt      # μμ„± μ²λ¦¬ ν¨ν‚¤μ§€
β”‚   β”β”€β”€ requirements_finetuning.txt # μΌλ° νμΈνλ‹ ν¨ν‚¤μ§€
β”‚   β””β”€β”€ toefl_evaluations_template.csv  # CSV ν…ν”λ¦Ώ
β”‚
β””β”€β”€ π“ λ°μ΄ν„° (μ‚¬μ©μ μ¤€λΉ„)
    β”β”€β”€ audio/                      # WAV νμΌλ“¤
    β”‚   β”β”€β”€ student_1.wav
    β”‚   β”β”€β”€ student_2.wav
    β”‚   β””β”€β”€ ...
    β””β”€β”€ feedback.csv                # λ€λ³Έ + ν”Όλ“λ°±
```

---

## π― μ‹μ¤ν… κµ¬μ„±

### 1οΈβƒ£ λ°μ΄ν„° μ¤€λΉ„ λ‹¨κ³„ (`dataset_preparation/`)

```bash
# μ „μ²΄ μλ™ν™”
cd dataset_preparation
python create_full_dataset.py \
  --audio_dir ../audio \
  --csv ../feedback.csv \
  --train_audio_model
```

**μ¶λ ¥**:
- `processed_data/audio_features.jsonl`: μμ„± νΉμ§•
- `models/audio_model/`: LSTM λ¨λΈ
- `processed_data/training_data_*.jsonl`: LLM λ°μ΄ν„°

---

### 2οΈβƒ£ λ¨λΈ ν•™μµ λ‹¨κ³„ (GPU μ„λ²„)

#### Option A: M2 Mac (MLX)
```bash
python finetune_m2_mac.py
# β†’ models/toefl_finetuned_mlx/
```

#### Option B: GPU μ„λ²„ (HuggingFace)
```bash
python finetune_huggingface.py
# β†’ models/toefl_finetuned_model/
```

---

### 3οΈβƒ£ ν‰κ°€/λ°°ν¬ λ‹¨κ³„ (M2 Mac)

#### ν†µν•© ν‰κ°€ μ‹μ¤ν…
```bash
python integrated_evaluation_system.py \
  --audio student.wav \
  --transcript "I prefer studying..." \
  --audio_model ./models/audio_model \
  --llm_type mlx
```

#### API μ„λ²„
```bash
python api_server_mlx.py
# β†’ http://localhost:5000
```

---

## π€ λΉ λ¥Έ μ‹μ‘ μ‹λ‚λ¦¬μ¤

### μ‹λ‚λ¦¬μ¤ 1: μ²μλ¶€ν„° λκΉμ§€ (μ¶”μ²)

```bash
# 1. μ„¤μΉ
./setup_m2.sh

# 2. λ°μ΄ν„° μ¤€λΉ„ (μμ„± νΉμ§• + μμ„± λ¨λΈ + LLM λ°μ΄ν„°)
cd dataset_preparation
python create_full_dataset.py \
  --audio_dir ../audio \
  --csv ../feedback.csv \
  --train_audio_model

# 3. LLM νμΈνλ‹ (M2 Mac)
cd ..
python finetune_m2_mac.py

# 4. ν†µν•© ν‰κ°€ μ‹¤ν–‰
python integrated_evaluation_system.py \
  --audio audio/test.wav \
  --transcript "Your answer..." \
  --audio_model ./models/audio_model
```

---

### μ‹λ‚λ¦¬μ¤ 2: GPU μ„λ²„ ν™μ©

```bash
# === λ΅μ»¬ (M2 Mac) ===
# 1. μμ„± νΉμ§•λ§ μ¶”μ¶
cd dataset_preparation
python audio_feature_extraction.py \
  --audio_dir ../audio \
  --csv ../feedback.csv

# 2. LLM λ°μ΄ν„° μ¤€λΉ„
python prepare_training_data.py

# 3. GPU μ„λ²„λ΅ μ—…λ΅λ“
scp audio_features.jsonl user@gpu-server:/workspace/
scp training_data_huggingface.jsonl user@gpu-server:/workspace/

# === GPU μ„λ²„ ===
# 4. μμ„± λ¨λΈ ν•™μµ
python train_audio_model.py \
  --data audio_features.jsonl \
  --epochs 100

# 5. LLM νμΈνλ‹
python finetune_huggingface.py

# 6. λ¨λΈ λ‹¤μ΄λ΅λ“
scp -r user@gpu-server:/workspace/models ./

# === λ΅μ»¬ (M2 Mac) ===
# 7. ν†µν•© ν‰κ°€
python integrated_evaluation_system.py --audio test.wav ...
```

---

### μ‹λ‚λ¦¬μ¤ 3: LLMλ§ νμΈνλ‹

```bash
# μμ„± λ¶„μ„μ€ κΈ°μ΅΄ λ¨λΈ μ‚¬μ©, LLMλ§ νμΈνλ‹
cd dataset_preparation
python create_full_dataset.py \
  --csv ../feedback.csv \
  --only_llm_data \
  --llm_format huggingface

cd ..
python finetune_m2_mac.py
```

---

## π“ λ°μ΄ν„° νλ¦„

```
[μ›λ³Έ λ°μ΄ν„°]
  β”β”€β”€ audio/student_1.wav
  β””β”€β”€ feedback.csv
         β”‚
         β†“
[dataset_preparation/]
         β”‚
         β”β”€β†’ audio_feature_extraction.py
         β”‚      β†“
         β”‚   audio_features.jsonl (MFCC, Pitch, Energy...)
         β”‚      β†“
         β”‚   train_audio_model.py
         β”‚      β†“
         β”‚   models/audio_model/ (LSTM λ°μ/μ μ°½μ„± λ¨λΈ)
         β”‚
         β””β”€β†’ prepare_training_data.py
                β†“
             training_data_*.jsonl
                β†“
[νμΈνλ‹]
  β”β”€β”€ finetune_m2_mac.py β†’ models/toefl_finetuned_mlx/
  β””β”€β”€ finetune_huggingface.py β†’ models/toefl_finetuned_model/
         β”‚
         β†“
[ν†µν•© ν‰κ°€]
  integrated_evaluation_system.py
    β”β”€β”€ μμ„± β†’ audio_model β†’ λ°μ/μ μ°½μ„± μ μ
    β””β”€β”€ ν…μ¤νΈ β†’ LLM β†’ λ‚΄μ©/λ¬Έλ²• ν‰κ°€
         β”‚
         β†“
  μΆ…ν•© ν‰κ°€ λ¦¬ν¬νΈ (JSON)
```

---

## π“ μ‚¬μ© ν¨ν„΄λ³„ κ°€μ΄λ“

### ν¨ν„΄ 1: μ—°κµ¬/ν”„λ΅ν† νƒ€μ… (μ†κ·λ¨ λ°μ΄ν„°)
```bash
# 50-100κ° μƒν”λ΅ λΉ λ¥΄κ² ν…μ¤νΈ
cd dataset_preparation
python create_full_dataset.py \
  --audio_dir ../audio \
  --csv ../feedback.csv \
  --audio_epochs 50  # μ μ€ μ—ν¬ν¬

# M2 Macμ—μ„ νμΈνλ‹
python ../finetune_m2_mac.py
```

### ν¨ν„΄ 2: ν”„λ΅λ•μ… (λ€κ·λ¨ λ°μ΄ν„°)
```bash
# 500+ μƒν”λ΅ κ³ ν’μ§ λ¨λΈ
# GPU μ„λ²„ μ‚¬μ©

# 1. λ°μ΄ν„° μ¤€λΉ„
cd dataset_preparation
python create_full_dataset.py \
  --audio_dir ../audio \
  --csv ../feedback.csv \
  --no_train_audio  # GPU μ„λ²„μ—μ„ ν•™μµ

# 2. GPU μ„λ²„λ΅ μ—…λ΅λ“
# 3. GPU μ„λ²„μ—μ„ ν•™μµ
python train_audio_model.py --epochs 200
python finetune_huggingface.py

# 4. λ¨λΈ λ‹¤μ΄λ΅λ“ λ° λ°°ν¬
```

### ν¨ν„΄ 3: API μ„λΉ„μ¤
```bash
# ν•™μµλ λ¨λΈλ΅ API μ„λ²„ μ‹¤ν–‰
python api_server_mlx.py \
  --model mlx-community/Mistral-7B-Instruct-v0.2-4bit \
  --adapter ./models/toefl_finetuned_mlx \
  --port 5000

# λ‹¤λ¥Έ ν„°λ―Έλ„μ—μ„ ν…μ¤νΈ
curl -X POST http://localhost:5000/evaluate \
  -H "Content-Type: application/json" \
  -d '{"text": "I prefer studying..."}'
```

---

## π“ μ£Όμ” νμΌ μ—­ν• 

### λ°μ΄ν„° μ¤€λΉ„ λ„κµ¬
| νμΌ | μ—­ν•  | μ…λ ¥ | μ¶λ ¥ |
|------|------|------|------|
| `audio_feature_extraction.py` | μμ„± νΉμ§• μ¶”μ¶ | WAV + CSV | audio_features.jsonl |
| `train_audio_model.py` | LSTM λ¨λΈ ν•™μµ | audio_features.jsonl | models/audio_model/ |
| `prepare_training_data.py` | LLM λ°μ΄ν„° λ³€ν™ | CSV | training_data_*.jsonl |
| `create_full_dataset.py` | μ „μ²΄ νμ΄ν”„λΌμΈ | WAV + CSV | λ¨λ“  μ¶λ ¥ |

### νμΈνλ‹ λ„κµ¬
| νμΌ | ν”λ«νΌ | λ¨λΈ | νΉμ§• |
|------|--------|------|------|
| `finetune_m2_mac.py` | M2 Mac | Mistral-7B | MLX, λ¬΄λ£, λ΅μ»¬ |
| `finetune_huggingface.py` | GPU μ„λ²„ | Llama/Mistral | μ¤ν”μ†μ¤ |
| `finetune_openai.py` | ν΄λΌμ°λ“ | GPT-3.5/4 | κ°„λ‹¨, μ λ£ |

### μ‹¤ν–‰ λ„κµ¬
| νμΌ | μ—­ν•  | μ‚¬μ© μ‹κΈ° |
|------|------|----------|
| `integrated_evaluation_system.py` | ν†µν•© ν‰κ°€ | ν•™μµ ν›„ ν‰κ°€ |
| `api_server_mlx.py` | REST API | μ„λΉ„μ¤ λ°°ν¬ |

---

## π”§ ν™κ²½λ³„ μ„¤μ •

### M2 Mac
```bash
# μ„¤μΉ
./setup_m2.sh

# λλ” μλ™
pip install -r requirements_m2.txt
pip install -r requirements_audio.txt
```

### GPU μ„λ²„ (Linux)
```bash
pip install -r requirements_finetuning.txt
pip install -r requirements_audio.txt

# CUDA ν™•μΈ
python -c "import torch; print(torch.cuda.is_available())"
```

### Google Colab
```python
!pip install -r requirements_audio.txt
!pip install transformers datasets accelerate peft
```

---

## π’΅ ν & νΈλ¦­

### λΉ λ¥Έ ν…μ¤νΈ
```bash
# μƒν” λ°μ΄ν„°λ΅ μ „μ²΄ νμ΄ν”„λΌμΈ ν…μ¤νΈ
cd dataset_preparation
python create_full_dataset.py \
  --audio_dir ../audio_sample \
  --csv ../feedback_sample.csv \
  --audio_epochs 10  # λΉ λ¥΄κ²
```

### μ¦λ¶„ μ—…λ°μ΄νΈ
```bash
# μƒ λ°μ΄ν„° μ¶”κ°€ μ‹
python audio_feature_extraction.py \
  --audio_dir ../audio_new \
  --csv ../feedback_new.csv \
  --output audio_features_new.jsonl

# λ³‘ν•©
cat audio_features.jsonl audio_features_new.jsonl > audio_features_all.jsonl
```

### λ””λ²„κΉ…
```bash
# λ‹¨κ³„λ³„ ν™•μΈ
python -c "
import json
with open('processed_data/audio_features.jsonl', 'r') as f:
    data = [json.loads(line) for line in f]
    print(f'μƒν” μ: {len(data)}')
    print(f'μ²« μƒν” ν‚¤: {data[0].keys()}')
"
```

---

## π“– μ¶”κ°€ λ¬Έμ„

- **λΉ λ¥Έ μ‹μ‘**: `QUICKSTART_M2.md`
- **μμ„± ν‰κ°€**: `AUDIO_MULTIMODAL_GUIDE.md`
- **M2 Mac μ„¤μ •**: `M2_MAC_SETUP.md`
- **νμΈνλ‹ μ΄λ΅ **: `FINETUNING_GUIDE.md`
- **λ°μ΄ν„° μ¤€λΉ„**: `dataset_preparation/README.md`

---

## β… μ²΄ν¬λ¦¬μ¤νΈ

ν”„λ΅μ νΈ μ‹μ‘:
- [ ] `./setup_m2.sh` μ‹¤ν–‰
- [ ] `audio/` ν΄λ”μ— WAV νμΌ μ¤€λΉ„
- [ ] `feedback.csv` νμΌ μ¤€λΉ„

λ°μ΄ν„° μ¤€λΉ„:
- [ ] `create_full_dataset.py` μ‹¤ν–‰
- [ ] `audio_features.jsonl` μƒμ„± ν™•μΈ
- [ ] μμ„± λ¨λΈ ν•™μµ μ™„λ£

νμΈνλ‹:
- [ ] LLM λ°μ΄ν„° μƒμ„± ν™•μΈ
- [ ] M2 Mac λλ” GPU μ„λ²„μ—μ„ νμΈνλ‹
- [ ] λ¨λΈ μ €μ¥ ν™•μΈ

λ°°ν¬:
- [ ] ν†µν•© ν‰κ°€ μ‹μ¤ν… ν…μ¤νΈ
- [ ] API μ„λ²„ μ‹¤ν–‰ (μ„ νƒ)

---

**μ²΄κ³„μ μΈ ν”„λ΅μ νΈ κµ¬μ΅°λ΅ ν¨μ¨μ μΈ κ°λ°μ„ ν•μ„Έμ”!** π€
