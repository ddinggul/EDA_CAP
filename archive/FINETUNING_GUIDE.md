# TOEFL μ¤ν”Όν‚Ή ν‰κ°€ LLM νμΈνλ‹ κ°€μ΄λ“

## π“‹ λ©μ°¨
1. [λ°μ΄ν„° μ¤€λΉ„](#1-λ°μ΄ν„°-μ¤€λΉ„)
2. [ν”λ«νΌ μ„ νƒ](#2-ν”λ«νΌ-μ„ νƒ)
3. [νμΈνλ‹ μ‹¤ν–‰](#3-νμΈνλ‹-μ‹¤ν–‰)
4. [ν‰κ°€ λ° λ°°ν¬](#4-ν‰κ°€-λ°-λ°°ν¬)
5. [λΉ„μ© λ° λ¦¬μ†μ¤](#5-λΉ„μ©-λ°-λ¦¬μ†μ¤)

---

## 1. λ°μ΄ν„° μ¤€λΉ„

### 1.1 ν„μ¬ λ°μ΄ν„° ν„ν™©
- **μ»¬λΌ κµ¬μ΅°**: ν…μ¤νΈ, νμΌμ΄λ¦„, ν…μ¤νΈν”Όλ“λ°±, λ°μ, fluency, λ‚΄μ©, λ¬Έλ²•/ν‘ν„, total_score
- **μµμ† ν•„μ” λ°μ΄ν„°**: 50-100κ° μƒν” (κ¶μ¥: 200κ° μ΄μƒ)
- **λ°μ΄ν„° ν’μ§**: μΌκ΄€λ ν‰κ°€ κΈ°μ¤€, λ…ν™•ν• ν”Όλ“λ°±

### 1.2 CSV νμΌ μ¤€λΉ„
```bash
# CSV νμΌ κµ¬μ΅° μμ‹
python prepare_training_data.py
```

### 1.3 λ°μ΄ν„° κ²€μ¦
- λ¨λ“  μ»¬λΌμ— λ„λ½λ κ°’ ν™•μΈ
- ν‰κ°€ μ μμ μΌκ΄€μ„± ν™•μΈ (0-4μ )
- ν”Όλ“λ°± λ‚΄μ©μ κµ¬μ²΄μ„± ν™•μΈ

---

## 2. ν”λ«νΌ μ„ νƒ

### μµμ… 1: OpenAI Fine-tuning (μ¶”μ² β­)
**μ¥μ :**
- κ°„λ‹¨ν• API μ‚¬μ©
- κ³ ν’μ§ κ²°κ³Ό
- λΉ λ¥Έ ν•™μµ μ‹κ°„ (λ‡ μ‹κ°„)
- μΈν”„λΌ κ΄€λ¦¬ λ¶ν•„μ”

**λ‹¨μ :**
- λΉ„μ© λ°μƒ ($0.008/1K tokens ν•™μµ)
- λ¨λΈ μ†μ κ¶ μ—†μ

**μ ν•©ν• κ²½μ°:**
- λΉ λ¥Έ ν”„λ΅ν† νƒ€μ…
- λ†’μ€ ν’μ§ μ”κµ¬
- μΈν”„λΌ κ΄€λ¦¬ λ¶€λ‹΄ νν”Ό

```bash
pip install openai
python finetune_openai.py
```

**λΉ„μ© μμƒ:**
- 100κ° μƒν” (ν‰κ·  500 ν† ν°): $4-10
- 1000κ° μƒν”: $40-100

---

### μµμ… 2: HuggingFace (μ¤ν”μ†μ¤)
**μ¥μ :**
- μ™„μ „ν• λ¨λΈ μ†μ κ¶
- μ»¤μ¤ν„°λ§μ΄μ§• μμ λ„ λ†’μ
- μ¥κΈ°μ μΌλ΅ λΉ„μ© μ κ°

**λ‹¨μ :**
- GPU ν•„μ” (VRAM 12GB μ΄μƒ)
- κΈ°μ μ  λ³µμ΅λ„ λ†’μ
- ν•™μµ μ‹κ°„ κΈΈμ (μ μ‹κ°„~μμΌ)

**μ ν•©ν• κ²½μ°:**
- μ¥κΈ° μ΄μ κ³„ν
- λ¨λΈ μ™„μ „ μ μ–΄ ν•„μ”
- GPU λ¦¬μ†μ¤ ν™•λ³΄

**κ¶μ¥ λ¨λΈ:**
1. **Llama-2-7b-chat** (κ¶μ¥): κ· ν•μ΅ν μ„±λ¥
2. **Mistral-7B-Instruct**: λΉ λ¥΄κ³  ν¨μ¨μ 
3. **Gemma-7b-it**: Google λ¨λΈ, ν•κµ­μ–΄ μ§€μ›

```bash
pip install transformers datasets peft accelerate bitsandbytes
python finetune_huggingface.py
```

**λ¦¬μ†μ¤ μ”κµ¬μ‚¬ν•­:**
- GPU: NVIDIA RTX 3090 μ΄μƒ (24GB VRAM)
- RAM: 32GB μ΄μƒ
- μ €μ¥κ³µκ°„: 50GB μ΄μƒ

**λ¬΄λ£ GPU μµμ…:**
- Google Colab (λ¬΄λ£ T4 GPU, μ ν•μ )
- Kaggle Notebooks (μ£Ό 30μ‹κ°„ λ¬΄λ£)

---

### μµμ… 3: Google Gemini Fine-tuning
**μ¥μ :**
- κ°•λ ¥ν• λ‹¤κµ­μ–΄ μ§€μ›
- ν•©λ¦¬μ μΈ κ°€κ²©
- Google Cloud ν†µν•©

**λ‹¨μ :**
- μƒλ€μ μΌλ΅ μƒλ΅μ΄ ν”λ«νΌ
- λ¬Έμ„ λ¶€μ΅±

```bash
pip install google-generativeai
# Gemini API ν‚¤ ν•„μ”
```

---

## 3. νμΈνλ‹ μ‹¤ν–‰

### 3.1 λ°μ΄ν„° λ³€ν™
```bash
# CSV β†’ JSONL λ³€ν™
python prepare_training_data.py

# μ„ νƒν•  ν•μ‹:
# 1. OpenAI
# 2. HuggingFace
# 3. Gemini
```

### 3.2 ν•™μµ μ‹¤ν–‰

#### OpenAI λ°©μ‹:
```bash
# API ν‚¤ μ„¤μ •
export OPENAI_API_KEY='your-key-here'

# νμΈνλ‹ μ‹¤ν–‰
python finetune_openai.py
```

#### HuggingFace λ°©μ‹:
```bash
# Hugging Face λ΅κ·ΈμΈ
huggingface-cli login

# νμΈνλ‹ μ‹¤ν–‰ (GPU ν•„μ”!)
python finetune_huggingface.py
```

### 3.3 ν•μ΄νΌνλΌλ―Έν„° νλ‹
```python
# μ£Όμ” μ„¤μ •κ°’
hyperparameters = {
    "n_epochs": 3,           # μ—ν¬ν¬ μ (3-5 κ¶μ¥)
    "learning_rate": 2e-4,   # ν•™μµλ¥ 
    "batch_size": 4,         # λ°°μΉ ν¬κΈ°
}
```

**κ¶μ¥μ‚¬ν•­:**
- λ°μ΄ν„° 50κ° λ―Έλ§: epochs=5
- λ°μ΄ν„° 100-500κ°: epochs=3
- λ°μ΄ν„° 500κ° μ΄μƒ: epochs=2

---

## 4. ν‰κ°€ λ° λ°°ν¬

### 4.1 λ¨λΈ ν…μ¤νΈ
```python
# test_model.py
from openai import OpenAI

client = OpenAI()

response = client.chat.completions.create(
    model="ft:gpt-3.5-turbo:your-model-id",
    messages=[
        {"role": "system", "content": "λ‹Ήμ‹ μ€ TOEFL ν‰κ°€ μ „λ¬Έκ°€μ…λ‹λ‹¤."},
        {"role": "user", "content": "λ‹µλ³€μ„ ν‰κ°€ν•΄μ£Όμ„Έμ”: ..."}
    ]
)

print(response.choices[0].message.content)
```

### 4.2 μ„±λ¥ ν‰κ°€ μ§€ν‘
- **μΌκ΄€μ„±**: κ°™μ€ λ‹µλ³€μ— λ€ν• λ°λ³µ ν‰κ°€ μΌμΉλ„
- **μ •ν™•μ„±**: μ‹¤μ  ν‰κ°€μμ™€μ μ μ μ°¨μ΄ (RMSE)
- **ν”Όλ“λ°± ν’μ§**: κµ¬μ²΄μ μ΄κ³  μ‹¤ν–‰ κ°€λ¥ν• ν”Όλ“λ°± μ κ³µ μ—¬λ¶€

### 4.3 A/B ν…μ¤νΈ
```python
# κΈ°μ΅΄ λ¨λΈ vs νμΈνλ‹ λ¨λΈ λΉ„κµ
test_cases = [...]
for case in test_cases:
    original = evaluate_with_base_model(case)
    finetuned = evaluate_with_finetuned_model(case)
    compare(original, finetuned)
```

---

## 5. λΉ„μ© λ° λ¦¬μ†μ¤

### 5.1 OpenAI λΉ„μ©
| ν•­λ© | κ°€κ²© | μμƒ λΉ„μ© |
|------|------|----------|
| ν•™μµ (100 μƒν”) | $0.008/1K tokens | $5-10 |
| μ¶”λ΅  (1000ν) | $0.012/1K tokens | $10-20 |
| **μ›” μ΄ λΉ„μ©** | | **$50-100** |

### 5.2 HuggingFace λΉ„μ©
| ν•­λ© | κ°€κ²© | μμƒ λΉ„μ© |
|------|------|----------|
| GPU μ„λ²„ (A100) | $1-3/hour | ν•™μµ μ‹ $10-50 |
| μ¶”λ΅  (μμ²΄ νΈμ¤ν…) | μ„λ²„ λΉ„μ© | $50-200/μ›” |

### 5.3 κ¶μ¥ μ‹μ‘ μ „λµ
1. **ν”„λ΅ν† νƒ€μ… λ‹¨κ³„**: OpenAI GPT-3.5 ($50-100)
2. **κ²€μ¦ λ‹¨κ³„**: 100κ° μƒν”λ΅ ν…μ¤νΈ
3. **μ¤μΌ€μΌμ—…**: λ°μ΄ν„° 500κ° μ΄μƒ μμ§‘
4. **ν”„λ΅λ•μ…**: HuggingFaceλ΅ μ΄μ „ (μ¥κΈ° λΉ„μ© μ κ°)

---

## 6. λ‹¨κ³„λ³„ μ‹¤ν–‰ μ²΄ν¬λ¦¬μ¤νΈ

### β… 1λ‹¨κ³„: λ°μ΄ν„° μ¤€λΉ„
- [ ] CSV νμΌμ— μµμ† 50κ° μƒν” ν™•λ³΄
- [ ] λ¨λ“  μ»¬λΌ λ„λ½κ°’ μ²λ¦¬
- [ ] ν‰κ°€ κΈ°μ¤€ λ¬Έμ„ν™”

### β… 2λ‹¨κ³„: ν™κ²½ μ„¤μ •
- [ ] Python 3.8+ μ„¤μΉ
- [ ] ν•„μ” λΌμ΄λΈλ¬λ¦¬ μ„¤μΉ
- [ ] API ν‚¤ λ°κΈ‰ (OpenAI or HuggingFace)

### β… 3λ‹¨κ³„: λ°μ΄ν„° λ³€ν™
- [ ] `prepare_training_data.py` μ‹¤ν–‰
- [ ] JSONL νμΌ κ²€μ¦
- [ ] λ°μ΄ν„° ν’μ§ ν™•μΈ

### β… 4λ‹¨κ³„: νμΈνλ‹
- [ ] ν•™μµ μ¤ν¬λ¦½νΈ μ‹¤ν–‰
- [ ] ν•™μµ μ§„ν–‰ λ¨λ‹ν„°λ§
- [ ] λ¨λΈ ID μ €μ¥

### β… 5λ‹¨κ³„: ν…μ¤νΈ
- [ ] ν…μ¤νΈ μΌ€μ΄μ¤ 10κ° μ¤€λΉ„
- [ ] νμΈνλ‹ λ¨λΈλ΅ ν‰κ°€
- [ ] κΈ°μ΅΄ ν‰κ°€μ™€ λΉ„κµ

### β… 6λ‹¨κ³„: λ°°ν¬
- [ ] API μ—”λ“ν¬μΈνΈ κµ¬μ¶•
- [ ] μ›Ή μΈν„°νμ΄μ¤ μ—°κ²°
- [ ] λ¨λ‹ν„°λ§ μ„¤μ •

---

## 7. λ¬Έμ  ν•΄κ²°

### Q1: λ°μ΄ν„°κ°€ λ¶€μ΅±ν• κ²½μ°?
**A:** Few-shot learning μ‚¬μ©
```python
# ν”„λ΅¬ν”„νΈμ— μμ‹ ν¬ν•¨
examples = """
μμ‹ 1:
λ‹µλ³€: "I like reading books..."
ν‰κ°€: λ°μ 3.5, μ μ°½μ„± 3.0, ...

μμ‹ 2:
...
"""
```

### Q2: λ¨λΈμ΄ μΌκ΄€μ„±μ΄ μ—†λ” κ²½μ°?
**A:** Temperature λ‚®μ¶”κΈ°
```python
temperature=0.3  # λ” μΌκ΄€λ κ²°κ³Ό
```

### Q3: GPUκ°€ μ—†λ” κ²½μ°?
**A:**
1. Google Colab μ‚¬μ© (λ¬΄λ£)
2. OpenAI μ‚¬μ© (GPU λ¶ν•„μ”)
3. Runpod, Lambda Labs (μ €λ ΄ν• GPU λ νƒ)

---

## 8. μ¶”κ°€ κ°μ„  λ°©μ•

### 8.1 μμ„± μΈμ‹ ν†µν•©
```python
import whisper

# μμ„± β†’ ν…μ¤νΈ
model = whisper.load_model("base")
text = model.transcribe("audio.mp3")

# ν…μ¤νΈ ν‰κ°€
evaluation = evaluate_toefl_speaking(text)
```

### 8.2 λ°μ λ¶„μ„ μ¶”κ°€
```python
# Azure Speech Services μ‚¬μ©
from azure.cognitiveservices.speech import SpeechConfig

# λ°μ μ μ μ¶”μ¶
pronunciation_score = analyze_pronunciation(audio_file)
```

### 8.3 μ‹¤μ‹κ°„ ν”Όλ“λ°±
```python
# WebSocketμΌλ΅ μ‹¤μ‹κ°„ ν‰κ°€
import asyncio
import websockets

async def evaluate_stream(websocket):
    audio = await websocket.recv()
    text = transcribe(audio)
    evaluation = evaluate(text)
    await websocket.send(evaluation)
```

---

## 9. μ°Έκ³  μλ£

- [OpenAI Fine-tuning κ°€μ΄λ“](https://platform.openai.com/docs/guides/fine-tuning)
- [HuggingFace PEFT λ¬Έμ„](https://huggingface.co/docs/peft)
- [LoRA λ…Όλ¬Έ](https://arxiv.org/abs/2106.09685)
- [TOEFL ν‰κ°€ κΈ°μ¤€](https://www.ets.org/toefl)

---

## 10. μ—°λ½μ² λ° μ§€μ›

λ¬Έμ κ°€ λ°μƒν•λ©΄:
1. GitHub Issues ν™•μΈ
2. HuggingFace Forums
3. OpenAI Community

**μ„±κ³µμ μΈ νμΈνλ‹μ„ κΈ°μ›ν•©λ‹λ‹¤! π€**
