"""
OpenAI GPT λ¨λΈ νμΈνλ‹ μ¤ν¬λ¦½νΈ
GPT-3.5-turbo λλ” GPT-4λ¥Ό TOEFL μ¤ν”Όν‚Ή ν‰κ°€μ— λ§κ² νμΈνλ‹
"""

import openai
import json
import time
from pathlib import Path

# API ν‚¤ μ„¤μ • (ν™κ²½λ³€μ λλ” μ§μ ‘ μ…λ ¥)
# export OPENAI_API_KEY='your-api-key-here'
openai.api_key = "YOUR_API_KEY"  # λλ” os.getenv("OPENAI_API_KEY")


def upload_training_file(file_path: str):
    """ν•™μµ λ°μ΄ν„° νμΌμ„ OpenAIμ— μ—…λ΅λ“"""
    print(f"π“¤ νμΌ μ—…λ΅λ“ μ¤‘: {file_path}")

    with open(file_path, "rb") as f:
        response = openai.File.create(
            file=f,
            purpose="fine-tune"
        )

    file_id = response["id"]
    print(f"β… νμΌ μ—…λ΅λ“ μ™„λ£! File ID: {file_id}")
    return file_id


def create_fine_tune_job(training_file_id: str, model: str = "gpt-3.5-turbo"):
    """νμΈνλ‹ μ‘μ—… μ‹μ‘"""
    print(f"\nπ€ νμΈνλ‹ μ‹μ‘...")
    print(f"λ¨λΈ: {model}")

    response = openai.FineTuningJob.create(
        training_file=training_file_id,
        model=model,
        hyperparameters={
            "n_epochs": 3,  # μ—ν¬ν¬ μ (3-4 κ¶μ¥)
        }
    )

    job_id = response["id"]
    print(f"β… νμΈνλ‹ μ‘μ—… μƒμ„± μ™„λ£! Job ID: {job_id}")
    return job_id


def monitor_fine_tune_job(job_id: str):
    """νμΈνλ‹ μ§„ν–‰ μƒν™© λ¨λ‹ν„°λ§"""
    print(f"\nπ‘€ νμΈνλ‹ μ§„ν–‰ μƒν™© λ¨λ‹ν„°λ§...")

    while True:
        response = openai.FineTuningJob.retrieve(job_id)
        status = response["status"]

        print(f"μƒνƒ: {status}")

        if status == "succeeded":
            print(f"\nβ… νμΈνλ‹ μ™„λ£!")
            print(f"λ¨λΈ ID: {response['fine_tuned_model']}")
            return response["fine_tuned_model"]
        elif status == "failed":
            print(f"\nβ νμΈνλ‹ μ‹¤ν¨")
            print(f"μ—λ¬: {response.get('error', 'Unknown error')}")
            return None

        time.sleep(60)  # 1λ¶„λ§λ‹¤ ν™•μΈ


def test_fine_tuned_model(model_id: str, test_text: str):
    """νμΈνλ‹λ λ¨λΈ ν…μ¤νΈ"""
    print(f"\nπ§ λ¨λΈ ν…μ¤νΈ μ¤‘...")

    response = openai.ChatCompletion.create(
        model=model_id,
        messages=[
            {
                "role": "system",
                "content": "λ‹Ήμ‹ μ€ TOEFL μ¤ν”Όν‚Ή ν‰κ°€ μ „λ¬Έκ°€μ…λ‹λ‹¤."
            },
            {
                "role": "user",
                "content": f"λ‹¤μ ν•™μƒμ λ‹µλ³€μ„ ν‰κ°€ν•΄μ£Όμ„Έμ”:\n\n{test_text}"
            }
        ],
        temperature=0.7,
        max_tokens=500
    )

    result = response.choices[0].message.content
    print("\nν‰κ°€ κ²°κ³Ό:")
    print(result)
    return result


if __name__ == "__main__":
    print("=" * 60)
    print("OpenAI GPT νμΈνλ‹ for TOEFL μ¤ν”Όν‚Ή ν‰κ°€")
    print("=" * 60)

    # 1. ν•™μµ λ°μ΄ν„° νμΌ μ—…λ΅λ“
    training_file = "training_data_openai.jsonl"

    if not Path(training_file).exists():
        print(f"β {training_file} νμΌμ΄ μ—†μµλ‹λ‹¤.")
        print("λ¨Όμ € prepare_training_data.pyλ¥Ό μ‹¤ν–‰ν•μ„Έμ”.")
        exit(1)

    file_id = upload_training_file(training_file)

    # 2. νμΈνλ‹ μ‘μ—… μ‹μ‘
    # gpt-3.5-turbo (μ €λ ΄) λλ” gpt-4 (κ³ ν’μ§) μ„ νƒ
    model_choice = "gpt-3.5-turbo-0125"  # λλ” "gpt-4-0613"
    job_id = create_fine_tune_job(file_id, model=model_choice)

    # 3. μ‘μ—… λ¨λ‹ν„°λ§
    fine_tuned_model = monitor_fine_tune_job(job_id)

    # 4. ν…μ¤νΈ
    if fine_tuned_model:
        test_text = """From my perspective, I prefer to study subjects that interest them.
That's because I think that it is important to find a job that is suitable for my interests."""

        test_fine_tuned_model(fine_tuned_model, test_text)

        print(f"\nβ… νμΈνλ‹λ λ¨λΈ IDλ¥Ό μ €μ¥ν•μ„Έμ”: {fine_tuned_model}")
        with open("fine_tuned_model_id.txt", "w") as f:
            f.write(fine_tuned_model)
